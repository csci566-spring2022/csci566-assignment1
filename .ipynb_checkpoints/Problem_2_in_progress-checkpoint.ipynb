{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Incorporating CNNs\n",
    "\n",
    "* Learning Objective: In this problem, you will learn how to deeply understand how Convolutional Neural Networks work by implementing one.\n",
    "* Provided Code: We provide the skeletons of classes you need to complete. Forward checking and gradient checkings are provided for verifying your implementation as well.\n",
    "* TODOs: you will implement a Convolutional Layer and a MaxPooling Layer to improve on your classification results in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.mlp.fully_conn import *\n",
    "from lib.mlp.layer_utils import *\n",
    "from lib.mlp.datasets import *\n",
    "from lib.mlp.train import *\n",
    "from lib.cnn.layer_utils import *\n",
    "from lib.cnn.cnn_models import *\n",
    "from lib.grad_check import *\n",
    "from lib.optim import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data (SVHN)\n",
    "Run the following code block to download SVHN dataset and load in the properly splitted SVHN data. The script `get_datasets.sh` use `wget` to download the SVHN dataset. If you have a trouble with executing `get_datasets.sh`, you can manually download the dataset and extract files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-06 12:53:03--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
      "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 182040794 (174M) [text/plain]\n",
      "Saving to: ‘data/train_32x32.mat.3’\n",
      "\n",
      "train_32x32.mat.3   100%[===================>] 173.61M  5.84MB/s    in 33s     \n",
      "\n",
      "2022-02-06 12:53:36 (5.33 MB/s) - ‘data/train_32x32.mat.3’ saved [182040794/182040794]\n",
      "\n",
      "--2022-02-06 12:53:36--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
      "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64275384 (61M) [text/plain]\n",
      "Saving to: ‘data/test_32x32.mat.2’\n",
      "\n",
      "test_32x32.mat.2    100%[===================>]  61.30M  6.59MB/s    in 11s     \n",
      "\n",
      "2022-02-06 12:53:47 (5.67 MB/s) - ‘data/test_32x32.mat.2’ saved [64275384/64275384]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./get_datasets.sh\n",
    "# !get_datasets.sh for windows users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: data_train Shape: (70000, 3, 32, 32)\n",
      "Name: labels_train Shape: (70000,)\n",
      "Name: data_val Shape: (3257, 3, 32, 32)\n",
      "Name: labels_val Shape: (3257,)\n",
      "Name: data_test Shape: (26032, 3, 32, 32)\n",
      "Name: labels_test Shape: (26032,)\n"
     ]
    }
   ],
   "source": [
    "data = SVHN_data()\n",
    "for k, v in data.items():\n",
    "    print (\"Name: {} Shape: {}\".format(k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "We will use convolutional neural networks to try to improve on the results from Problem 1. Convolutional layers make the assumption that local pixels are more important for prediction than far-away pixels. This allows us to form networks that are robust to small changes in positioning in images.\n",
    "\n",
    "### Convolutional Layer Output size calculation\n",
    "\n",
    "As you have learned, two important parameters of a convolutional layer are its stride and padding. To warm up, we will need to calculate the output size of a convolutional layer given its stride and padding. To do this, open the `lib/cnn/layer_utils.py` file and fill out the TODO section in the `get_output_size` function in the ConvLayer2D class. \n",
    "\n",
    "Implement you function so that it returns the correct size as indicated by the blocck below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received [32, 16, 16, 16] and expected [32, 16, 16, 16]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "input_image = np.zeros([32, 28, 28, 3]) # a stack of 32 28 by 28 rgb images\n",
    "\n",
    "in_channels = input_image.shape[-1] #must agree with the last dimension of the input image\n",
    "k_size = 4 \n",
    "n_filt = 16\n",
    "\n",
    "conv_layer = ConvLayer2D(in_channels, k_size, n_filt, stride=2, padding=3)\n",
    "output_size = conv_layer.get_output_size(input_image.shape) \n",
    "\n",
    "print(\"Received {} and expected [32, 16, 16, 16]\".format(output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer Forward Pass\n",
    "\n",
    "Now, we will implement the forward pass of a convolutional layer. Compare your output with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received output shape: (1, 4, 4, 2), Expected output shape: (1, 4, 4, 2)\n",
      "Difference:  5.110565335399418e-08\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "# Test the convolutional forward function\n",
    "input_image = np.linspace(-0.1, 0.4, num=1*8*8*1).reshape([1, 8, 8, 1]) # a single 8 by 8 grayscale image\n",
    "in_channels, k_size, n_filt = 1, 5, 2\n",
    "\n",
    "weight_size = k_size*k_size*in_channels*n_filt\n",
    "bias_size = n_filt\n",
    "\n",
    "\n",
    "\n",
    "single_conv = ConvLayer2D(in_channels, k_size, n_filt, stride=1, padding=0, name=\"conv_test\")\n",
    "\n",
    "w = np.linspace(-0.2, 0.2, num=weight_size).reshape(k_size, k_size, in_channels, n_filt)\n",
    "b = np.linspace(-0.3, 0.3, num=bias_size)\n",
    "\n",
    "single_conv.params[single_conv.w_name] = w\n",
    "single_conv.params[single_conv.b_name] = b\n",
    "\n",
    "out = single_conv.forward(input_image)\n",
    "\n",
    "print(\"Received output shape: {}, Expected output shape: (1, 4, 4, 2)\".format(out.shape))\n",
    "\n",
    "correct_out = np.array([[\n",
    "   [[-0.03874312, 0.57000324],\n",
    "   [-0.03955296, 0.57081309],\n",
    "   [-0.04036281, 0.57162293],\n",
    "   [-0.04117266, 0.57243278]],\n",
    "\n",
    "  [[-0.0452219, 0.57648202],\n",
    "   [-0.04603175, 0.57729187],\n",
    "   [-0.04684159, 0.57810172],\n",
    "   [-0.04765144, 0.57891156]],\n",
    "\n",
    "  [[-0.05170068, 0.5829608 ],\n",
    "   [-0.05251053, 0.58377065],\n",
    "   [-0.05332038, 0.5845805 ],\n",
    "   [-0.05413022, 0.58539035]],\n",
    "\n",
    "  [[-0.05817946, 0.58943959],\n",
    "   [-0.05898931, 0.59024943],\n",
    "   [-0.05979916, 0.59105928],\n",
    "   [-0.06060901, 0.59186913]]]])\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer Backward\n",
    "\n",
    "Now calculate the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimg Error:  2.971524190210189e-08\n",
      "dw Error:  5.097641295265651e-09\n",
      "db Error:  1.9005853572949477e-10\n",
      "dimg Shape:  (15, 8, 8, 3) (15, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "# Test the conv backward function\n",
    "img = np.random.randn(15, 8, 8, 3)\n",
    "w = np.random.randn(4, 4, 3, 12)\n",
    "b = np.random.randn(12)\n",
    "dout = np.random.randn(15, 4, 4, 12)\n",
    "\n",
    "single_conv = ConvLayer2D(input_channels=3, kernel_size=4, number_filters=12, stride=2, padding=1, name=\"conv_test\")\n",
    "single_conv.params[single_conv.w_name] = w\n",
    "single_conv.params[single_conv.b_name] = b\n",
    "\n",
    "dimg_num = eval_numerical_gradient_array(lambda x: single_conv.forward(img), img, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: single_conv.forward(img), w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: single_conv.forward(img), b, dout)\n",
    "\n",
    "out = single_conv.forward(img)\n",
    "\n",
    "dimg = single_conv.backward(dout)\n",
    "dw = single_conv.grads[single_conv.w_name]\n",
    "db = single_conv.grads[single_conv.b_name]\n",
    "\n",
    "# The error should be around 1e-8\n",
    "print(\"dimg Error: \", rel_error(dimg_num, dimg))\n",
    "# The errors should be around 1e-8\n",
    "print(\"dw Error: \", rel_error(dw_num, dw))\n",
    "print(\"db Error: \", rel_error(db_num, db))\n",
    "# The shapes should be same\n",
    "print(\"dimg Shape: \", dimg.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling Layer\n",
    "\n",
    "### Forward Pass max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received output shape: (1, 3, 3, 1), Expected output shape: (1, 3, 3, 1)\n",
      "Difference:  1.8750000280978013e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the convolutional forward function\n",
    "input_image = np.linspace(-0.1, 0.4, num=64).reshape([1, 8, 8, 1]) # a single 8 by 8 grayscale image\n",
    "\n",
    "maxpool= MaxPoolingLayer(pool_size=4, stride=2, name=\"maxpool_test\")\n",
    "out = maxpool.forward(input_image)\n",
    "\n",
    "print(\"Received output shape: {}, Expected output shape: (1, 3, 3, 1)\".format(out.shape))\n",
    "\n",
    "correct_out = np.array([[\n",
    "   [[0.11428571],\n",
    "   [0.13015873],\n",
    "   [0.14603175]],\n",
    "\n",
    "  [[0.24126984],\n",
    "   [0.25714286],\n",
    "   [0.27301587]],\n",
    "\n",
    "  [[0.36825397],\n",
    "   [0.38412698],\n",
    "   [0.4       ]]]])\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimg Error:  3.2761294284588474e-12\n",
      "dimg Shape:  (15, 8, 8, 3) (15, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randn(15, 8, 8, 3)\n",
    "\n",
    "dout = np.random.randn(15, 3, 3, 3)\n",
    "\n",
    "maxpool= MaxPoolingLayer(pool_size=4, stride=2, name=\"maxpool_test\")\n",
    "\n",
    "dimg_num = eval_numerical_gradient_array(lambda x: maxpool.forward(img), img, dout)\n",
    "\n",
    "out = maxpool.forward(img)\n",
    "dimg = maxpool.backward(dout)\n",
    "\n",
    "# The error should be around 1e-8\n",
    "print(\"dimg Error: \", rel_error(dimg_num, dimg))\n",
    "# The shapes should be same\n",
    "print(\"dimg Shape: \", dimg.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a Small Fully Connected Network [2pt]\n",
    "Please find the SmallFullyConnectedNetwork function in lib/cnn/cnn_models.py.\n",
    "Again you only need to complete few lines of code in the TODO block.\n",
    "Please design a Convolutional --> Maxpool --> flatten --> fc network where the shapes of parameters match the given shapes.\n",
    "Please insert the corresponding names you defined for each layer to param_name_w, and param_name_b respectively.\n",
    "Here you only modify the param_name part, the _w, and _b are automatically assigned during network setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Passed!\n",
      "Testing test-time forward pass ... \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c259b4cf0aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m correct_scores = np.asarray([[-13.85107294, -11.52845818,  -9.20584342,  -6.88322866,  -4.5606139 ],\n\u001b[1;32m     55\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11.44514171\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10.21200524\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m8.97886878\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m7.74573231\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m6.51259584\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/csci566-assignment1/lib/mlp/fully_conn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feat, is_training, seed)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/csci566-assignment1/lib/cnn/layer_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 output[:, i, j, :] = np.sum(\n\u001b[1;32m    150\u001b[0m                     \u001b[0mpadded_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mw_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 )\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = TestCNN()\n",
    "loss_func = cross_entropy()\n",
    "\n",
    "B, H, W, iC = 4, 8, 8, 3 #batch, height, width, in_channels\n",
    "k = 3 #kernel size\n",
    "oC, Hi, O = 3, 27, 5 # out channels, Hidden Layer input, Output size\n",
    "std = 0.02\n",
    "x = np.random.randn(B,H,W,iC)\n",
    "y = np.random.randint(O, size=B)\n",
    "\n",
    "print (\"Testing initialization ... \")\n",
    "\n",
    "###################################################\n",
    "# TODO: param_name should be replaced accordingly  #\n",
    "###################################################\n",
    "w1_std = abs(model.net.get_params(\"param_name_w\").std() - std)\n",
    "b1 = model.net.get_params(\"param_name_b\").std()\n",
    "w2_std = abs(model.net.get_params(\"param_name_w\").std() - std)\n",
    "b2 = model.net.get_params(\"param_name_b\").std()\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "assert w1_std < std / 10, \"First layer weights do not seem right\"\n",
    "assert np.all(b1 == 0), \"First layer biases do not seem right\"\n",
    "assert w2_std < std / 10, \"Second layer weights do not seem right\"\n",
    "assert np.all(b2 == 0), \"Second layer biases do not seem right\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing test-time forward pass ... \")\n",
    "w1 = np.linspace(-0.7, 0.3, num=k*k*iC*oC).reshape(k,k,iC,oC)\n",
    "w2 = np.linspace(-0.2, 0.2, num=Hi*O).reshape(Hi, O)\n",
    "b1 = np.linspace(-0.6, 0.2, num=oC)\n",
    "b2 = np.linspace(-0.9, 0.1, num=O)\n",
    "\n",
    "###################################################\n",
    "# TODO: param_name should be replaced accordingly  #\n",
    "###################################################\n",
    "model.net.assign(\"param_name_w\", w1)\n",
    "model.net.assign(\"param_name_b\", b1)\n",
    "model.net.assign(\"param_name_w\", w2)\n",
    "model.net.assign(\"param_name_b\", b2)\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "feats = np.linspace(-5.5, 4.5, num=B*H*W*iC).reshape(B,H,W,iC)\n",
    "scores = model.forward(feats)\n",
    "correct_scores = np.asarray([[-13.85107294, -11.52845818,  -9.20584342,  -6.88322866,  -4.5606139 ],\n",
    " [-11.44514171, -10.21200524 , -8.97886878 , -7.74573231 , -6.51259584],\n",
    " [ -9.03921048,  -8.89555231 , -8.75189413 , -8.60823596,  -8.46457778],\n",
    " [ -6.63327925 , -7.57909937 , -8.52491949 , -9.4707396 , -10.41655972]])\n",
    "scores_diff = np.sum(np.abs(scores - correct_scores))\n",
    "assert scores_diff < 1e-6, \"Your implementation might be wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the loss ...\",)\n",
    "y = np.asarray([0, 2, 1, 4])\n",
    "loss = loss_func.forward(scores, y)\n",
    "dLoss = loss_func.backward()\n",
    "correct_loss = 4.56046848799693\n",
    "assert abs(loss - correct_loss) < 1e-10, \"Your implementation might be wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the gradients (error should be no larger than 1e-6) ...\")\n",
    "din = model.backward(dLoss)\n",
    "for layer in model.net.layers:\n",
    "    if not layer.params:\n",
    "        continue\n",
    "    for name in sorted(layer.grads):\n",
    "        f = lambda _: loss_func.forward(model.forward(feats), y)\n",
    "        grad_num = eval_numerical_gradient(f, layer.params[name], verbose=False)\n",
    "        print ('%s relative error: %.2e' % (name, rel_error(grad_num, layer.grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network\n",
    "In this section, we defined a SmallConvolutionalNetwork class for you to fill in the TODO block in `lib/cnn/cnn_models.py`.\n",
    "\n",
    "Here please design a network with at most two convolutions, two maxpooling layers, two batch norms (you may use less).\n",
    "You can adjust the parameters for any layer, and include layers other than those listed above that you have implemented.\n",
    "You are also free to select any optimizer you have implemented.\n",
    "\n",
    "Try to find a combination that is able to achieve a 25% testing accuracy. Hint: if you are getting errors when training, check to see that the images are being supplied to the network in the correct shape.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange the data\n",
    "data_dict = {\n",
    "    \"data_train\": (data[\"data_train\"][:7500], data[\"labels_train\"][:7500]),\n",
    "    \"data_val\": (data[\"data_val\"][:1000], data[\"labels_val\"][:1000]),\n",
    "    \"data_test\": (data[\"data_test\"][:1000], data[\"labels_test\"][:1000])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (7500, 3, 32, 32)\n",
      "Flattened data input size: 3072\n",
      "Number of data classes: 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", data_dict[\"data_train\"][0].shape)\n",
    "print(\"Flattened data input size:\", np.prod(data[\"data_train\"].shape[1:]))\n",
    "print(\"Number of data classes:\", max(data['labels_train']) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-641e45d2f767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#                             END OF YOUR CODE                              #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m results = train_net(data_dict, model, loss_f, optimizer, batch_size, epochs, \n\u001b[0m\u001b[1;32m     25\u001b[0m                     lr_decay, lr_decay_every, show_every=30, verbose=True)\n\u001b[1;32m     26\u001b[0m \u001b[0mopt_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/csci566-assignment1/lib/mlp/train.py\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(data, model, loss_func, optimizer, batch_size, max_epochs, lr_decay, lr_decay_every, show_every, verbose)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# Show the training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mshow_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"(Iteration {} / {}) loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# End of epoch, compute the accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = SmallConvolutionalNetwork()\n",
    "loss_f = cross_entropy()\n",
    "\n",
    "\n",
    "results = None\n",
    "#############################################################################\n",
    "# TODO: Use the train_net function you completed to train a network         #\n",
    "#############################################################################\n",
    "optimizer = SGD(model.net, 1e-3)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "lr_decay = .999\n",
    "lr_decay_every = 10\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "results = train_net(data_dict, model, loss_f, optimizer, batch_size, epochs, \n",
    "                    lr_decay, lr_decay_every, show_every=30, verbose=True)\n",
    "opt_params, loss_hist, train_acc_hist, val_acc_hist = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Layers\n",
    "\n",
    "An interesting finding from early research in convolutional networks was that the learned convolutions resembled filters used for things like edge detection. Complete the code below to visualize the filters in the first convolutional layer of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lib.cnn.cnn_models.SmallConvolutionalNetwork object at 0x7efd1cf23f10>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
